---
title: "[TensorFlow] MNIST 필기체 숫자 인식하기"
excerpt: "Doit! 딥러닝 교과서 Ch2 실습1"
categories: [MachineLearning]
tags: [ML, DL, tensorflow]
toc: true
toc_sticky: true
---

## TensorFlow 설정하기
### TensorFlow import하기
```python
import tensorflow as tf
print("TensorFlow version: ", tf.__version__)
```
* __version__: 버전 확인 가능


## Dataset 로드하기
### MNIST 데이터 세트 로드
```python
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0         # 샘플 데이터를 정수에서 부동 소숫점 숫자로 변환
```
> [ 파이썬 문법 ] <br>
> a, b = 1, 2
> * a에는 1, b에는 2가 저장


## 머신러닝 모델 빌드하기
### keras.Sequential 모델 생성

```python
# 모델 생성
model = tf.keras.models.Sequential([                # keras의 기본 모델 구조(층을 차례대로 쌓음)
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation="relu"),  # 68개의 유닛을 가진 층을 추가
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation="softmax") # 10개의 출력유닛을 가진 소프트맥스 층 추가
])
```
keras.models
* Sequential: keras의 기본 모델 구조(층을 겹겹이 쌓음)

keras.layers
* Flatten:
* Dense:
   * activation: 층의 활성화 함수 설정
* Dropout:

### compile 메서드로 학습 과정 설정
```python
model.compile(optimizer="adam", 
              loss="sparse_categorical_crossentropy", 
              metrics=["accuracy"])
```
.compile의 핵심 매개변수 세개 + a
* optimizer: 훈련 과정 설정
* loss: 최적화 과정에서 최소화 될 손실 함수(loss function)를 설정
* metrics: 훈련을 모니터링하기 위해 사용
  
* (추가)모델의 훈련과 평가를 즉시 실행하려면 run_eagerly=True 매개변수 전달


```python
preditions = model(x_train[:1]).numpy() # 각 클래스에 대한 스코어 벡터 반환
preditions 
```
각 클래스에 대한 스코어 벡터를 로짓(logits) 또는 (log-odds)스코어 벡터로 반환
* 로짓 함수: (쉽게 말해) 시그모이드 함수의 역함수

```python
tf.nn.softmax(preditions).numpy()   # 로짓을 각 클래스에 대한 확률로 변환
```
로짓을 각 클래스에 대한 확률로 변환

### 손실 함수 정의
```python
# 손실 함수 정의 -> 찾아볼 것
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # 각 예시에 대해 스칼라 손실 반환
```

```python
loss_fn(y_train[:1], preditions).numpy()    # 훈련되지 않은 모델의 초기 손실
```
출력결과: 2.318909
* 해당 모델은 훈련되지 않았기 때문에 무작위에 가까운확률 제공(총 클래스 개수 10개 -> 각 클래스당 확률 1/10)
* 실제 클래스의 음의 로그 확률
   * tf.math.log(1/10) ~= 2.3
* 모델이 훈련되어 올바른 클래스를 확신하는 경우 손실: 0

위의 손실 함수(loss_fn)으로 모델 컴파일
```python
# 훈련 시작 전 모델을 구성하고 컴파일
model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])
```

## 모델 훈련 및 평가하기
### fit() 메서드로 만든 모델을 학습
```python
# 만든 모델을 학습(fit() 함수)
hist = model.fit(x_train, y_train, epochs=10)
```
model.fit(x, y, batch_size=32, epochs=10)
* x: 입력 데이터
* y: 라벨 값
* batch_size:몇 개의 샘플로 가중치를 갱신
* epochs: 학습 반복 횟수

```python
# 모델 성능 확인
model.evaluate(x_train, y_train, verbose=2)
```
model.evauate: 모델의 최종적인 정답률과 loss값을 반환
* 0 번째 인덱스: loss
* 1 번째 인덱스: 정답률

```python
# 모델이 확률을 반환
probability_model = tf.keras.Sequential([
    model,
    tf.keras.layers.Softmax()
])

probability_model(x_test[:5])   # 무슨 의미일까
```

<br/>

*** 

### Link
[텐서플로 2.0 시작하기](https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ko)