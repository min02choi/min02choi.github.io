---
title: "[TF] 머신러닝 개념 (Part2)"
excerpt: ""
categories: [MachineLearning]
tags: [ML]
toc: true
toc_sticky: true
---


## 1. 오리엔테이션
TF을 이용해서 해결하려는 문제는 지도학습의 분류와 회귀 문제
회귀: 숫자로 된 결과를 예측하는 것
분류: 범주형을 예측

의사결정나무, 랜덤포레스트, KNN, SVM, Neural Network 알고리즘을 이용하여 해결

Neural Network(인공신경망)
사람이 두뇌가 동작하는 모습을 모방해서 기계가 학습을 할수 있도록 고안된 알고리즘

인공신경망을 깊게 쌓으면 딥러닝이 됨
인간의 신경을 모방

인공지능 안에 기계학습 안에 딥러닝

앞으로 텐서플로우 라이브러리를 이용하여 딥러닝 할 것임
* 텐서플로우, 파이토치, 카페2, 테노(theano)라이브러리 등이 있음. 딥러닝을 코드로 구현할 수 있게 해줌


## 2. 목표와 전략


## 3. 지도학습의 빅픽쳐
1. 과거의 데이터 준비 - 원인과 결과를 인식하기(독립변수, 종속변수)
2. 모델의 구조를 만들기
3. 데이터로 모델을 학습함
4. 모델을 이용


## 4. 환경설정
코랩 설명


## 5. 표를 다루는 도구 '판다스'
독립변수와 종속변수를 분리하는 작업이 필요


## 6. 표를 다루는 도구 '판다스'(실습)
파일 불러와서 칼럼들 중 독립변수, 종속변수 나누기


## 7. 레모네이드 판매 예측
3 의 내용 설명


## 8. 손실의 의미
손실: 실제값과 예측값의 차의 제곱에 평균
손실이 0이면 좋은거임
학습을 할수록 loss가 줄어듦


## 9. 레모네이드 판매 예측(실습)


## 10. 보스톤 집값예측
설명변수가 한개가 아님


## 11. 수식과 퍼셉트론
퍼셉트론, 편향, 가중치 설명


## 13. 학습의 실체(with 워크북)
오 살짝 어렵구먼 - 이거 좀 다시 볼것


## 14. 아이리스 품종 분류
범주형 데이터임
양적 -> 회귀
범주형 -> 분류


## 15. 원한 핫코딩
모든 범주들을 column으로 만들어줌
해당 범주에 해당하는 column에 1로, 나머지는 0으로 함

딥러닝 하려면 모든 범주형 변수를 원핫인코딩 해주어야 함

pd.get_dummies(아이리스) 하면 모든 범주형 데이터를 판다스가 원핫인코딩 해줌

종속변수가 3개가 되어버림(iris 품종은 3가지 종류가 있음)


## 16. softmax
분류를 추측
* 내일 비가 온다/안온다

우리는 0~1사이의 결과를 원함
y1 = w1x1 + w2x2 + w3x3 + w4x4 + b
(이를 모든 종속변수에 대해서 식을 찾음)

위 수식을 softmax 함수로 감싸주면 원라는 결과가 나옴
y1 = softmax(w1x1 + w2x2 + w3x3 + w4x4 + b)

회귀의 결과에 함수를 하나 더 감싼 모양

* 회귀모델: y = x
* 분류모델: Softmax

활성화 함수: 퍼셉트론의 출력이 어떠한 형태로 나가야하는지 조절하는 역할

학습의 목표: loss 최소화하기
* 분류에서 사용하는 loss: cross entropy
* 회귀에서 사용하는 loss: mse

범주형 데이터를 확률의 개념으로 마주하기


## 18. 히든레이어
입력하는 부분: input layer
출력하는 부분: output layer

그 사이의 층: 히든 레이어
퍼셉트론..

각각의 모델을 연속적으로 연결하여 하나의 모델을 만드는 것이 딥러닝, 인공신경망