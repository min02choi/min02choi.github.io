---
title: "[TensorFlow] 텐서"
excerpt: ""
categories: [MachineLearning]
tags: [ML, DL, tensorflow]
toc: true
toc_sticky: true
---

## 기초

### 텐서 생성하기
#### TensorFlow 임포트
````python
import tensorflow as tf
import numpy as np
````

#### 기본 텐서 생성하기
* 스칼라: 단일, 순위0, 축 없음
* 벡터: 순위1, 축 1개
* 행렬: 순위2, 축 2개
* n개의 축 가능

```python
rank_0_tensor = tf.constant(4)    # 스칼라
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])    # 벡터
rank_2_tensor = tf.constant([[1, 2], [3, 4], [5, 6]], dtype = tf.float16)   # 행렬
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])
```
* 복소수, 문자열 가능
* 기본 tf.Tensor 클래스에서는 텐서가 직사각형 이어야 함
* 다양한 형상을 처리하는 특수 유형의 텐서: 비정형 텐서(RaggedTensor), 희소 텐서(SparseTensor)

#### 텐서를 numpy배열로 변환
```python
np.array(rank_2_tensor)     # 첫 번째 방법
rank_2_tensor.numpy()       # 두 번째 방법
```

#### 텐서에 대한 기본 산술
```python
a = tf.constant([[1, 2], [3, 4]])
b = tf.constant([[5, 6], [7, 8]])

# 표현법1
print(tf.add(a, b), "\n")       # 동일한 위치에 있는 원소의 합
print(tf.multiply(a, b), "\n")  # 동일한 위치에 있는 원소의 곱
print(tf.matmul(a, b), "\n")    # 행렬의 곱

print(a + b, "\n")    # 동일한 위치에 있는 원소의 합
print(a * b, "\n")    # 동일한 위치에 있는 원소의 곱
print(a @ b, "\n")    # 행렬의 곱
```

```python
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

print(tf.reduce_max(c))     # 변수에서 가장 큰 값을 탐색
print(tf.math.argmax(c))    # 가장 큰 값의 인덱스 값을 찾음
print(tf.nn.softmax(c))     # 
```
* softmax

## 형상 정보
### 텐서 관련 용어
* 형상: 텐서의 각 차원의 길이(요소의 수)
* 순위: 텐서 축의 수
* 축/차원: 텐서의 특정 차원
* 크기: 텐서의 총 항목 수, 형상 요소의 곱