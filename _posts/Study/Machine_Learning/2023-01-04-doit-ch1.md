---
title: "[Doit! 딥러닝 교과서] Ch1. 딥러닝 개요"
excerpt: "딥러닝이란?"
categories: [MachineLearning]
tags: [ML, DL]
toc: true
toc_sticky: true
---

# Ch1.1 딥러닝이란?

## 1.1.1 인공지능, 머신러닝과 딥러닝 정의
### 인공지능(AI, Artificial Intelligence)
문제를 인식하고 해결하는 능력인 지능을 구현하는 기술

### 머신러닝(ML, Machine Learning)
기계 스스로 학습하여 지능을 습득하는 기술
* 인공지능을 만드는 기술
* 학습 알고리즘을 통해 기계 스스로 습득 후, 결과를 이용하여 새로운 것을 예측, 추론

### 딥러닝(DL, Deep Learning)
인공 신경망을 이용해 복잡한 데이터 관계를 찾아내는 머신러닝 기법
* 인공 신경망이 깊은 긴경망으로 발전하여 '딥러닝'이라는 이름이 붙음

> 인공지능
> > 머신러닝
> > > 딥러닝

## 1.1.2 머신러닝과 딥러닝의 관계
* 작은 규모의 단순한 문제 -> 머신러닝 기법
* 머신러닝 기법으로 해결할 수 없는 문제, 복잡한 문제 -> 딥러닝
* 딥러닝은 머신러닝 기법에 종속되지 않음

### 머신러닝 기법 구분
#### 지도 학습
입력 데이터에 대한 정답을 사전에 정의해서 학습 데이터로 제공
* 분류
* 회귀: 데이터의 함수적 관계를 알아냄

#### 비지도 학습
전문가의 개입 없이 순수하게 데이터만으로 학습
* 클러스터링: 비슷한 데이터끼리 묶어줌
* 차원 축소: 고차원 데이터 -> 저차원 데이터 변환
* 데이터 생성
* 연관 규칙: 데이터 간의 규칙을 찾아냄

#### 강화 학습
순차적인 의사결정 방법 학습(보상을 최대화하는 행동을 선택하도록 학습)
한 번만 추론하는 지도학습/비지도학습보다  더 일반적인 문제를 다룸
* 비디오 게임, 보드게임 등

> * 딥러닝은 현재 지도학습에서 뛰어난 성과
> * 기존 머신러닝 알고리즘에 딥러닝이 접목될 때 -> 이름 앞에 '심층을 붙여서 구분'
> ex) 심층 비지도 학습


## 1.1.3 딥러닝의 장점과 한계

### 딥러닝의 장점
1. 함수를 근사하는 능력이 뛰어남
   * 비선형 함수를 근사할 때 뛰어난 성능

2. 특징을 자동적으로 추출
   * 중요한 특징에 높은 가중치, 그렇지 않은 것에는 낮은 가중치
   * 사람의 개입 없이 특징에 의미 부여(편향 적음)

3. 모델의 확장성이 뛰어남
   * 딥러닝 모델은 뉴런 연결로 되어 있으므로 큰 모델이 필요한 경우 뉴런 수를 늘려주면 됨 
   * 뉴련 -> 병렬처리 가능한 구조 -> 모델 대규모 확장 용이
   
4. 기존 머신러닝보다 좋은 성능

### 딥러닝의 한계
1. 딥러닝 모델은 파라미터가 많으므로 다른 머신러닝 모델보다 상대적으로 많은 학습데이터가 필요
   * 머신러닝과 달리 딥러닝은 범용적이기 때문에모델 파라미터, 학습 데이터가 많음
   * 데이터 양이 많으면 딥러닝 모델 크기 증가 가능 -> 데이터 많은 대기업일수록 유리

2. 훈련을 위한 시간과 비용이 많이 들음
   * 훈련 과정에서 데이터가 많이 필요하므로 훈련 시간과 컴퓨팅 자원도 데이터 양에 비례하여 증가
   * 이를 극복하기 위한 전이 학습, 메타 학습, 평생 학습 등

3. 설정 파라미터가 많아 상당히 많은 검색 시간과 튜닝 시간이 필요
   * 신경망 구조 탐색(최적의 딥러닝 모델을 자동으로 찾아줌) 연구 개발 진행

4. 인공 신경망 모델은 오류 파악이나 디버깅하기 어려움
   * XAI(explainable AI) 등의 기법 연구 진행

5. 지도학습에서는 타겟 데이터를 만들 때 드는 비용이 많음
   * 준 지도 학습, 자기 지도 학습 방식에 대한 연구 증가


***

# Ch1.2 인공 신경망의 탄생

## 1.2.1 지능을 만들고 싶은 인간

### 지능
어떠한 문제에 당면했을 때 자신의 지식과 경험을 활용하여 문제를 해결하는 능력
* 광법위한 인식 능력, 문제해결 능력 포괄
* 인간의 지능은 매우 높음
  * 주어진 환경에 순응X, 자신에게 맞춰 환경 변화
  * 자신의 노동력을 대체할 수 있는 도구 제작
* 인간들은 '지능을 가진 기계'를 만들고 싶어 함

## 1.2.2 뇌, 신경망 그리고 지능

지능을 만드는 방법? -> 생체 지능 모방!

### 생체 지능
1890년대, 뉴런주의 주장
* 뉴런주의: 뇌의 기능 단위는 뉴런
* 뉴런이 흥분하면 인접한 뉴런의 전기적 상태에 영향을 미침

### 생체 신경망

우리 몸에는 뉴런으로 구성된 거대한 생체 신경망 존재
* 외부에서 들어온 자극은 뉴런을 통해 전달
  * 뉴런 내부: 전기신호
  * 뉴런 사이(시냅스): 신경전달물질

* 시냅스 가소성: 신호를 전달하는 뉴런이 자주 활성화 될 때 신호 전달을 강화하기 위해 시냅스 구조가 변하는 성질
* 헵의 학습 가설: 지속해서 활성화 되는 뉴런은 연결된다


* 학습과 기억의 현상
  * 새로운 신호가 연관된 기억을 만나면 연결이 추가되며 관련된 기억 간의 연결 강화
  * 활성화 되지 않은 뉴런은 약화

> 시냅스의 연결이 강화되거나 약해지는 과정에서 기억 형성

***

# Ch1.3 딥러닝의 역사

* 인공 신경망의 발전은 생체 신경망 연구의 발전과 관련
* 인공지능을 구현하기 위해 필수적인 요소들
  * 대규모 컴퓨팅 자원
  * 생체 신경망의 실체


## 1.3.1 최초의 인공 신경망: 매컬러-피츠 모델

### 메털러 피츠-모델
최초의 이진 신경망 모델
* 이진 뉴런(활성화/비활성화 상태)으로 구성
* 생체 뉴련과 같이 시냅스의 흥분과 억제에 따라 신호 전달, 특정 임계치를 넘어야 신호 발화
* 이후 현대 AI의 창시자이자 현대 컴퓨터의 구조를 제시한 폰 노이만에 영향

한계점
* 학습 과정이 없음 -> 문제에 따라 신경망의 구성을 바꾸어야 함


## 1.3.2 학습하는 인공 신경망: 퍼셉트론

### 퍼셉트론
헵의 학습 가설에 따라 인공 신경망이 스스로 문제에 맞춰 학습하는 모델
* 새로운 입력에 대한 오차 발생 시 뉴런의 연결 강도 조절하는 학습방식
* 매컬러-피츠 모델의 단점 해결
* 두 종류의 클래스를 직선으로 분류하는 선형 분류기
* 결정 경계: 두 클래스를 구분하는 입력 데이터와 가중 합산 식
  * z = w1x1 + w2x2 + b = 0
  * 가중치(w1, w2): 직선의 법선 벡터
  * 편향 b: 원점과 직선 사이의 거리
* 퍼셉트론의 데이터를 처리하는 과정과 생체 뉴런의 신호 전달 과정은 유사

### 퍼셉트론의 구조
입력 데이터가 들어오면 가중치와 곱해서 가중 합산후 값이 0보다 크면 1출력, 그렇지 않으면 0 출력
* 가중 합산과 계단 함수를 순차적으로 실행


## 1.3.3 신경망 연구에 암흑기를 불러온 책 <<퍼셉트론>>

지능을 바라보는 두 관점(학파)
* 기호주의 학파: 실세계의 사물과 사상을 기호화하고 그들 사이에 관계를 정해주면 논리적 추론을 통해 지능을 만들 수 있음
* 연결주의 학파: 뉴런 수준에서 지능이 형성되는 과정을 모방하면 데이터로부터 스스로 지능을 만들 수 있음

### 퍼셉트론의 한계
기호주의 학파 마빈 민스키, 시모어 페퍼트가 주장한 한계
* 퍼셉트론은 비선형 문제를 풀 수 없음

다층 퍼셉트론: 퍼셉트론으로 비선형 문제를 풀려면 여러 퍼셉트론 계층이 필요


## 1.3.4 역전파 알고리즘의 발견

### 역전파 알고리즘
신경망의 뉴런에서 분산된 파라미터의 미분을 효율적으로 계산하기 위한 알고리즘
* 출력 계층에서 입력 계중 방향으로 한 계층씩 이동하며 미분 계산
* 다층 퍼셉트론 학습 가능하게 됨
* 비선형 문제 해결 가능


## 1.3.5 딥러닝 시대를 열다

### 인공지능망의 학습을 어렵게 만드는 요인
1. 과적합
   * 모델이 과도하게 학습되어 데이터를 암기한 상태
   * 그래프가 모델의 모든 점을 지나감

2. 그레이디언트 소실 문제
   * 역전파 과정에서 미분값이 사라지면서 학습이 중단되는 현상
   * 미분값이 0에 가까울수록 아주 작은 숫자가 여러번 곱해져 결국 0으로 수렴
   * 신경망이 깊어질수록 이런 현상이 두드러짐(학습이 어려워짐)

### 딥러닝
제프리 힌턴이 제시한 딥러닝 방법: 각 계층을 제한적 볼프만 머신으로 정의
* 사전 학습한 뒤에 한 계층씩 쌓아 올려 깊은 신경망을 만드는 방식
* 입력계층, 은닉 계층으로 이루어진 에너지 기반의 생성 모델

이후 드롭아웃 기법 제시
* 드롭 아웃: RBM의 사전 학습과 계층을 쌓는 전처리 과정 없이도 딥러닝 모델 학습 가능
