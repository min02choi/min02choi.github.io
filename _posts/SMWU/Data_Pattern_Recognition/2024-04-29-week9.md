---
title: "[Week9] Generative, Diffusion Model"
excerpt: "Generative, Diffusion Model"
categories: [DataPatternRecognition]
tags: [Model]
toc: true
toc_sticky: true
---


## Generative Models(생성 모델)
* 데이터의 분포를 학습함
* 분포 학습 후, 해당 분포에서 Sampling 하는 것을 “생성”이라고 칭함
* 생성: 특정 데이터의 분포를 학습 후, 학습된 분포에서 likelihood가 가장 높은 부분에서 sample를 추출하는 것
* Generative model Trilemma(트렐레마):

## Diffusion Model
* 지금까지의 생성 모델들은 input text(조건들)을 입력으로 받지 않음. 하지만 Text를 이미지로 바꾸어주는 Conditional Diffusion Model이 등장함

## Conditional Diffusion Model
Diffusion 아이디어: 이물질이 퍼져 나가는 과정을 NN에 학습시키고, 반대의 과정(회복)을 수행

### 1. DDPM(Denoising Diffusion Probabilistic Models)
*	확률적 과정으로 이미지를 생성하는 모델(학습에 사용된 데이터 속 이미지와 유사한 샘플들 생성)
*	이미지 생성은 노이즈를 점진적으로 제거하는 방식으로 이루어짐
*	DDPM의 모델 구조는 U-Net의 구조(input, output같은 차원)
*	모델 구성 요소, 잔차 블록, 다운샘플링 블록, attention layers, skip connection
*	Forward Process(q): 이미지가 완전한 “가우시안 노이즈”가 될 때까지 가우시안 노이즈를 점진적으로 추가하는 Markov Process
  * VAE에서 제안한 Reparameterization Trick:  
  * 현재 이미지가 주어졌을 때 1초 뒤 이미지는 평균이  , 분산이  인 가우시안 분포를 따름.(이전 값에 특정 스칼라 값을 곱하고, 특정 텐서값을 더함.)
  * Noise Schedule를수식적으로 정리하면 (500 수행) 한번에 가능: Forward Process를 진행할수록 1. 이미지 분포의 평균은 0에 근접하도록, 이미지 분포의 분산은 1에 근접하도록  Normal Gaussian 이 되도록
* Reverse Process(p): 가우시안 노이즈에서 점짐적으로 가우시안 노이즈를 제거해거 이미지를 복원하는 Markov Process
  * 분산을 고정하고, 평균값만을 학습함
  * Loss function: 사실상 log likelihood를 최대화  . 하지만 DDPM은 실제 분포를 몰라 유추 불가능  Proxy loss: Variational Lower Bound(VLB) 사용
* DDIM(Denoising Diffusion Implicit Model): DDPM모델에서 “noise의 단계별 정량화”를 시도
  * p시 Fast sampling이 가능, 원본 정보(x0)를 계속 공급함